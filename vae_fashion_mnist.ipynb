{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 305.5117 - val_loss: 284.3289\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 278.5633 - val_loss: 277.1826\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 274.1471 - val_loss: 274.4043\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 272.1260 - val_loss: 272.2098\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 270.9156 - val_loss: 271.6216\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 270.0000 - val_loss: 271.2759\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 269.1724 - val_loss: 269.2499\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 268.4472 - val_loss: 268.7571\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 267.8688 - val_loss: 268.3492\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 267.4001 - val_loss: 269.6174\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 266.9711 - val_loss: 267.9204\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 266.5865 - val_loss: 267.4492\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 266.2442 - val_loss: 268.6717\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 265.9328 - val_loss: 266.5947\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 265.7035 - val_loss: 266.4346\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 265.4304 - val_loss: 266.5356\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 265.2165 - val_loss: 266.4798\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 265.0581 - val_loss: 266.4711\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 264.8943 - val_loss: 266.4116\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 264.7224 - val_loss: 265.8345\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 264.5482 - val_loss: 265.9394\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 264.3954 - val_loss: 265.2129\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 264.2673 - val_loss: 265.9738\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 264.1111 - val_loss: 264.9357\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 264.0111 - val_loss: 265.0039\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 263.8746 - val_loss: 265.0725\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 263.7660 - val_loss: 264.8406\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 263.6770 - val_loss: 264.4438\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 263.5467 - val_loss: 264.8895\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 263.4660 - val_loss: 264.8193\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 263.3524 - val_loss: 264.7781\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 263.2964 - val_loss: 264.8612\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 263.1753 - val_loss: 264.1484\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 263.0890 - val_loss: 264.5111\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 263.0150 - val_loss: 264.8393\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 262.9275 - val_loss: 264.5631\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 262.8803 - val_loss: 264.4535\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 262.8114 - val_loss: 264.8888\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 262.7312 - val_loss: 264.3346\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 262.6524 - val_loss: 264.6486\n",
      "Epoch 41/50\n",
      "46400/60000 [======================>.......] - ETA: 0s - loss: 262.7075"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "batch_size = 100\n",
    "original_dim = 784\n",
    "intermediate_dim = 256\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(x, z_mean)\n",
    "\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "n = 20\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = np.linspace(-3, 3, n)\n",
    "grid_y = np.linspace(-3, 3, n)\n",
    "\n",
    "for i, xi in enumerate(grid_x):\n",
    "    for j, yi in enumerate(grid_y):\n",
    "        z_sample = np.array([[yi, xi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[(n - i - 1) * digit_size: (n - i) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
